{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Fidelity Synthetic Data generation notebook\n",
    "\n",
    "This notebook describes and implements the process of generating low-fidelity synthetic data from a collection of summary statistics.  It makes use of the `behavioural_synthetic` library built by the Behavioural Insights Team.  \n",
    "\n",
    "### Requirements:\n",
    "- Python 3.11 or greater.\n",
    "- R 4.4.1 or greater.  \n",
    "    - Required libraries: rlang, jsonlite, janitor, tidyverse, openxlsx.\n",
    "\n",
    "### Setup: \n",
    "- Copy the following into your working directory:\n",
    "    - The `behavioural_synthetic` directory.\n",
    "    - The `requirements.txt` file.\n",
    "    - The `QA_code.R` file.\n",
    "        - Set the `lib.loc` parameter in each `require` statement to the location of your R libraries.\n",
    "- Create a venv for Python using requirements.txt.\n",
    "- Set up the input and output directories.\n",
    "- Edit the notebook to use those input and output directories, as described later.\n",
    "- Run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and shared functions\n",
    "\n",
    "This section describes library imports and useful functions that will be used throughout the notebook.\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "from behavioral_synthetic.tables.Table import Table\n",
    "from behavioral_synthetic.tables.columns.general_functions import run_Rscript\n",
    "from behavioral_synthetic.tables.columns.general_functions import index_to_column, group_ids, individual_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "This contains the following useful functions:\n",
    "- `get_files_in_directory` -- returns a list of files in a directory\n",
    "- `is_file_in_directory` -- if file is in a list of files, return True, else return False.\n",
    "- `prepend_to_file` -- prepends a string to a file and writes it to disk.  Returns a dictionary containing the execution status (i.e. whether it worked) and any necessary error messages.\n",
    "- `write_log` -- writes a string to a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(directory: str) -> list:\n",
    "    return [file for file in listdir(directory) if isfile(join(directory, file))]\n",
    "\n",
    "def is_file_in_directory(file: str, files_in_dir) -> list:\n",
    "    return any(file in filename for filename in files_in_dir)\n",
    "    \n",
    "def prepend_to_file(data:str, file_name:str, new_file: str) -> dict:\n",
    "    try:\n",
    "        with open(file_name, 'r') as file:\n",
    "            file_data = file.read()\n",
    "        \n",
    "        prepended_data = \"# \"+ data + \"\\n\" + file_data\n",
    "        \n",
    "        with open(new_file, 'w') as file:\n",
    "            file.write(prepended_data)\n",
    "            \n",
    "        return {\n",
    "            \"successful\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"successful\": False,\n",
    "            \"error\": e\n",
    "        }\n",
    "        \n",
    "def write_log(message, logfile):\n",
    "        record = f'{datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S %Z\")}: {message}' + '\\n'\n",
    "        print(record)\n",
    "        with open(logfile, 'a') as file:\n",
    "            file.write(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output settings\n",
    "Here we set the following parameters:\n",
    "- `SOURCE_DIRECTORY` -- where the summary statistics are kept (in .json format). Note that you may need to convert exports from the SRS to this format using the `convert_from_srs.py` and `test_convert.py`utility.  The latter may need to be adapted according to your file structure.\n",
    "- `TARGET_DIRECTORY` -- this is where intermediate .tsv files will be stored prior to the QA run. Note that they won't have correct ID columns at this stage; this is done during the QA processing.\n",
    "- `METADATA_DIRECTORY` -- This is where the final results and any metadata related to them are stored.  It should have the following subdirectories:\n",
    "    - `categorical_metrics_comparison`\n",
    "    - `corr_p_values`\n",
    "    - `cumulative_distribution_plots`\n",
    "    - `numerical_metrics_comparison`\n",
    "- `OVERWRITE_SD` -- if a file with the same name as the one about to be generated exists, do we overwrite it? If `True` we do, otherwise we skip to the next dataset.\n",
    "\n",
    "The default values of the above and other variables in the following cell (e.g. `BATCH_NUMBER`) assume that we are processing the sum total of datasets in batches.  Please modify this as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_NUMBER=6\n",
    "\n",
    "SOURCE_DIRECTORY = f\" ... \\\\JSON files\\\\BATCH{BATCH_NUMBER}\"\n",
    "TARGET_DIRECTORY = f\" ... \\\\TSV files\\\\BATCH{BATCH_NUMBER}\"\n",
    "METADATA_TARGET_DIRECTORY= f\" ... \\\\Post QA files\\\\BATCH{BATCH_NUMBER}\"\n",
    "OVERWRITE_SD = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the data sets to process. We assume that the names of the summary statistics files are of the form `${data_set_name}${append}` where `${append}` is the same for all data sets and `${data_set_name}` is a value listed in `files_base`. Please adapt this to your preferred convention if needed. \n",
    "\n",
    "Do not include the file suffix (i.e. `.json`, `.txt`, etc.) -- this is handled by the code and doing so will result in error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_base = [\n",
    "\"File 1\",\n",
    "\"File 2\"\n",
    "]\n",
    "\n",
    "\n",
    "append = \"\"\n",
    "\n",
    "files = [f\"{file}{append}\" for file in files_base]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One: Generate synthetic data\n",
    "\n",
    "Running this will generate the intermediate files placed in `TARGET_DIRECTORY`.  For each data set in turn, it reads in the summary data and generates the corresponding synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create_log_file\n",
    "sd_logfile = f'{TARGET_DIRECTORY}\\\\SD_generation_log_{datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")}.txt'\n",
    "open(sd_logfile, 'w').close()\n",
    "\n",
    "\n",
    "files_in_target_directory = get_files_in_directory(TARGET_DIRECTORY)\n",
    "\n",
    "for file in files:\n",
    "    write_log(f\"{file}:\", sd_logfile)\n",
    "    if is_file_in_directory(file, files_in_target_directory) and OVERWRITE_SD == False:\n",
    "        write_log(\"Synthetic Data already generated\", sd_logfile)\n",
    "        continue\n",
    "    else :\n",
    "        write_log(\"Generating synthetic Data\", sd_logfile)\n",
    "        \n",
    "        input_file = f\"{SOURCE_DIRECTORY}\\\\{file}.json\"\n",
    "        output_file = f\"{TARGET_DIRECTORY}\\\\{file}.tsv\"\n",
    "        \n",
    "\n",
    "        with open(input_file, 'r') as file:\n",
    "            table_definition = json.load(file)\n",
    "        \n",
    "        table = Table(table=pd.DataFrame(), table_name=\"\")\n",
    "        table.read_in_table(table_definition)\n",
    "        synthetic_data = table.generate(new_column_length=table_definition['Number_of_rows'])\n",
    "\n",
    "        synthetic_data.to_csv(output_file, sep='\\t', index=False)\n",
    "        \n",
    "        write_log(\"Done!\", sd_logfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two: Generate QA and post-process synthetic data files\n",
    "\n",
    "Here we generate the QA data and post-process the synthetic data so that it has plausible ID columns and a datestamp.\n",
    "\n",
    "### Functions\n",
    "\n",
    "Here we define functions that are useful only for this stage of the process.  They include:\n",
    "-  `extract_QA_data` -- this converts the dataset name into a format where it matches the result in the R QA output file so it can be extracted.  At this point a lot of the conversions have been entered by hand, but it should be possible to replace them with a more compact regular expression. Returns a dictionary describing whether the operation worked and any relevant error messages.\n",
    "-  `clean_data` -- removes data with no correlation p-values. Columns where this is the case are logged in a warning file.\n",
    "-  `extract_correlations` -- extracts correlation p-values from the associated R QA output file.\n",
    "-  `get_cumulative_distribution` -- returns correlation p-values in the form of a cumulative distribution.\n",
    "-  `plot_cumulative_distribution` -- plots the cumulative distribution of p-values. Returns a dictionary describing whether the graphs was successfully generated and any relevant error messages.\n",
    "-  `generate_anon_ids` -- generates plausible id values for some id columns: \"Project_Row_ID\", \"Anon_Pupil_ID\", \"Anon_School_ID\", \"Anon_Teacher_ID\", \"Anon_Class_ID\". Returns a dictionary describing whether this was done successfully and any relevant error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_QA_data(directory,file_prefix, QA_type):\n",
    "    try:\n",
    "        with open(f\"{directory}\\\\{QA_type}\", 'r') as file:\n",
    "            data = json.load(file)\n",
    "        underlined_prefix = (file_prefix.replace(\" \", \"_\")\n",
    "                             .replace(\",\", \"_\")\n",
    "                             .replace(\"-\", \"_\")\n",
    "                             .replace(\"(\", \"_\")\n",
    "                             .replace(\")\",\"_\")\n",
    "                             .replace(\"___\",\"_\")\n",
    "                             .replace(\"__\", \"_\")\n",
    "                             .replace(\"extNow\", \"ext_now\")\n",
    "                             .replace(\"ThinkFor\", \"Think_For\")\n",
    "                             .replace(\"phoGame\", \"pho_Game\")\n",
    "                             .replace(\"ScratchMaths\", \"Scratch_Maths\")\n",
    "                             .replace(\"flectEd\", \"flect_ed\")\n",
    "                             .replace(\"1stClass@Number\", \"x1st_class_number\")\n",
    "                             .replace(\"SciNapse\", \"sci_napse\")\n",
    "                             .replace(\"FiveRs\", \"five_rs\")\n",
    "                             .replace(\"CraftOfWriting157\", \"craft_of_writing157\")\n",
    "                             .replace(\"YoungJournalistAcademy158\", \"young_journalist_academy158\")\n",
    "                             .replace(\"PowerOfPictures159\", \"power_of_pictures159\")\n",
    "                             .replace(\"FirstThingMusic160\", \"first_thing_music160\")\n",
    "                             .replace(\"SpeechBubbles161\", \"speech_bubbles161\")\n",
    "                             .lower())\n",
    "        selector=f\"{underlined_prefix}\"\n",
    "        QA_dir = QA_type.split('.')[0]\n",
    "    \n",
    "        with open(f\"{directory}\\\\{QA_dir}\\\\{file_prefix}_{QA_type}\", \"w\") as file:\n",
    "            json.dump(data[selector], file, indent=4)\n",
    "        return {\n",
    "            \"successful\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"successful\": False,\n",
    "            \"error\": e\n",
    "        }\n",
    "\n",
    "def clean_data(data, directory, correlation_file):\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for item in data:\n",
    "        if 'p_value' not in list(item.keys()):\n",
    "            message = f'The p-value for {item[\"Comparison_column_1\"]} and {item[\"Comparison_column_2\"]} correlations is missing:' +'\\n' +f'{item}'\n",
    "            with open(f\"{directory}\\\\..\\\\{correlation_file.split('.')[0]}_WARNING_notes.txt\", \"a\") as file:\n",
    "                file.write(message + \"\\n\")\n",
    "        else:\n",
    "            cleaned_data.append(item)\n",
    "    \n",
    "    return cleaned_data\n",
    "           \n",
    "\n",
    "def extract_correlations(directory, correlation_file):\n",
    "    \n",
    "    with open(f\"{directory}\\\\{correlation_file}\", 'r') as file:\n",
    "        data=json.load(file)\n",
    "        \n",
    "    cleaned_data = clean_data(data, directory, correlation_file)\n",
    "    \n",
    "    return [item['p_value'] for item in cleaned_data]\n",
    "\n",
    "def get_cumulative_distribution(directory, correlation_file):\n",
    "    \n",
    "    data_list = extract_correlations(directory,correlation_file) \n",
    "    fractional_distance = []\n",
    "    for i in range(len(data_list)):\n",
    "        fractional_distance.append((i+1)/len(data_list))\n",
    "\n",
    "    return {\"X\":fractional_distance, \"Y\": np.sort(data_list)}\n",
    "\n",
    "def plot_cumulative_distribution(directory, correlation_file):\n",
    "    try:\n",
    "        data = get_cumulative_distribution(directory, correlation_file)\n",
    "        #based on https://stackoverflow.com/posts/22588814/revisions\n",
    "        Comparison_X = data[\"X\"]\n",
    "        Comparison_Y = data[\"X\"]  #both are set equal to the X paramater to get linear curve with gradient 1, the ideal case\n",
    "        \n",
    "        file_prefix = correlation_file.split('.')[0]\n",
    "    \n",
    "        output = f\"{directory}\\\\..\\\\cumulative_distribution_plots\\\\{file_prefix}_cumulative_distribution.pdf\"\n",
    "    \n",
    "        plt.step(data['X'], data['Y'], label = 'synthetic data')\n",
    "        plt.step(Comparison_X,Comparison_Y, label = 'ideal case')\n",
    "        plt.title(file_prefix)\n",
    "        plt.xlabel(\"Fraction\")\n",
    "        plt.ylabel(\"p-value\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(output, format=\"pdf\")\n",
    "        plt.close()   \n",
    "        \n",
    "        return {\n",
    "            \"successful\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"successful\": False,\n",
    "            \"error\": e\n",
    "        }\n",
    "   \n",
    "def generate_anon_ids(no_meta_data_file, with_meta_data_file):\n",
    "    try:\n",
    "        dataframe = pd.read_csv(no_meta_data_file, sep='\\t', comment='#')\n",
    "        dataframe.to_csv(with_meta_data_file, sep='\\t')\n",
    "\n",
    "        #handling the anon/unique id columns:\n",
    "        id_column_list = [\"Project_Row_ID\", \"Anon_Pupil_ID\", \"Anon_School_ID\", \"Anon_Teacher_ID\", \"Anon_Class_ID\"]\n",
    "        no_rows = len(dataframe.index)\n",
    "        \n",
    "        for col in id_column_list:\n",
    "            if not dataframe[col].isna().all():\n",
    "                \n",
    "                if col == \"Project_Row_ID\":\n",
    "                    dataframe[col] = index_to_column(dataframe) #, \"Project_Row_ID\")\n",
    "                elif col == \"Anon_Pupil_ID\":\n",
    "                    dataframe[col] = individual_ids(4, 7, no_rows, False, True)\n",
    "                elif col == \"Anon_School_ID\":\n",
    "                    group_size = int(max(5,min(no_rows/50, 250 )))\n",
    "                    dataframe[col] = group_ids(4, 6, group_size, no_rows, False, True)\n",
    "                elif col == \"Anon_Teacher_ID\":\n",
    "                    group_size = int(max(5, min(no_rows/100, 80 ))) #set too close to 99 and it will take forever to finish\n",
    "                    dataframe[col] = group_ids(1, 2, group_size, no_rows, False, True)\n",
    "                elif col == \"Anon_Class_ID\":\n",
    "                    group_size = int(max(5, min(no_rows/100, 500 ))) # orginally set to have a max of 999, seems that slows it down in large cases\n",
    "                    dataframe[col] = group_ids(1, 3, group_size, no_rows, False, True)\n",
    "\n",
    "        dataframe.to_csv(with_meta_data_file, sep='\\t', index=False)\n",
    "    \n",
    "        return {\n",
    "            \"successful\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"successful\": False,\n",
    "            \"error\": e\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run QA and post-processing\n",
    "\n",
    "The value of `OVERWRITE_METADATA` determines whether individual QA files will be written over if they already exist.  Note that this does not affect the operation of the R script that generates the source files from which that data is extracted.\n",
    "\n",
    "The R script will generate output files corresponding to all files in the source and target directories.  For large collections of datasets it therefore makes sense to work in smaller batches of 10 or so datafiles, as in some cases the script can take up to 20 minutes to run.  The output will often include some warning messages.  These can usually be ignored.\n",
    "\n",
    "Once the R script has run, each dataset in the **Input and Output Settings** is processed in turn.  The relevant QA data is extracted from the R script output and saved in separate files. The intermediate .tsv file is processed to add id columns and a datestamp, and saved in the metadata output directory.\n",
    "\n",
    "**Note on cumulative density plots:** It is unlikely that individual plots will have more than a general resemblance to the ideal line plot displayed in the graph.  In order to be as sure as possible that the distribution of correlations is as close to chance as possible, use the `generate_overal_cd_plots.py` utility script.  It may need to be adapted in order to account for how you have decided to store your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_METADATA = False\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"INPUT_DIR\": f\"{SOURCE_DIRECTORY}\",\n",
    "    \"OUTPUT_DIR\": f\"{TARGET_DIRECTORY}\",\n",
    "    \"JSON_FILE_LOC\": f\"{METADATA_TARGET_DIRECTORY}\",\n",
    "        }\n",
    "\n",
    "#create_log_file\n",
    "qa_logfile = f'{METADATA_TARGET_DIRECTORY}\\\\QA_log_{datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")}.txt'\n",
    "open(qa_logfile, 'w').close()\n",
    "\n",
    "write_log(\"Generating metadata for batch\", qa_logfile)\n",
    "print(run_Rscript(settings))\n",
    "\n",
    "files_in_metadata_directory = get_files_in_directory(METADATA_TARGET_DIRECTORY)\n",
    "\n",
    "for file in files:\n",
    "    write_log(f\"{file}:\", qa_logfile)\n",
    "    output_types = [\"categorical_metrics_comparison.json\", \"corr_p_values.json\", \"numerical_metrics_comparison.json\", \"with_anon_ids.tsv\"]\n",
    "    generated = all([is_file_in_directory(f\"{file}_{output_type}\",files_in_metadata_directory) for output_type in output_types])\n",
    "    if generated and OVERWRITE_METADATA == False:\n",
    "        write_log(\"Metadata already extracted.\", qa_logfile)\n",
    "    else:\n",
    "        write_log(\"Extracting QA metadata (this will overwrite any old files)\", qa_logfile)\n",
    "       \n",
    "        no_meta_data_file = f\"{TARGET_DIRECTORY}\\\\{file}.tsv\"\n",
    "        with_meta_data_file = f\"{METADATA_TARGET_DIRECTORY}\\\\{file}_with_anon_ids.tsv\"\n",
    "\n",
    "        QA_files = output_types[0:3]\n",
    "        \n",
    "        for QA_file in QA_files:\n",
    "            write_log(f\"Extracting from: {QA_file}\", qa_logfile)\n",
    "            extract_QA_status = extract_QA_data(METADATA_TARGET_DIRECTORY, file, QA_file)\n",
    "            if not extract_QA_status[\"successful\"]:\n",
    "                write_log(f\"WARNING: problem extracting metadata for {file} from {QA_file}: {extract_QA_status['error']}\", qa_logfile)\n",
    "            \n",
    "       # generate anon ids for files -- take no_meta_data_File and outpurt as with_meta_data_file\n",
    "        \n",
    "        id_gen_status = generate_anon_ids(no_meta_data_file, with_meta_data_file)\n",
    "        if not id_gen_status[\"successful\"]:\n",
    "            write_log(f\"WARNING: problem adding ids to synthetic data: {id_gen_status['error']}\",qa_logfile)\n",
    "       \n",
    "        print('prepend data') \n",
    "        prepend_data= {}\n",
    "        prepend_data['Date generated'] = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S %Z\")\n",
    "        \n",
    "        prepend_status = prepend_to_file(json.dumps(prepend_data), with_meta_data_file, with_meta_data_file)\n",
    "        if not prepend_status[\"successful\"]:\n",
    "            write_log(f\"WARNING: problem prepending metadata to synthetic data: {prepend_status['error']}\",qa_logfile)\n",
    "            \n",
    "        plot_status = plot_cumulative_distribution(f\"{METADATA_TARGET_DIRECTORY}\\\\corr_p_values\", f\"{file}_corr_p_values.json\")\n",
    "        if not plot_status[\"successful\"]:\n",
    "           write_log(f\"WARNING: problem generating cumulative distribution plot: {plot_status['error']}\", qa_logfile)\n",
    "        \n",
    "        write_log(f\"Metadata processing for file {file} complete.\", qa_logfile)\n",
    "\n",
    "write_log(f\"Metadata processing for batch finished\", qa_logfile)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8e1ff98d5c64551dcd12239f36e0ba2d98afe903219bc0fa5dea9dbc8954af1"
  },
  "kernelspec": {
   "display_name": "Python 3.11.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
